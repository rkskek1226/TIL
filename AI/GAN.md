**인코더(Encoder)**

입력 데이터 x에 연관된 d차원의 입력 특성 베터를 받아 p차원의 벡터인 z로 인코딩 수행.

$$z = f(x$$)를 모델링하는 방법을 배우는 역할.

인코딩된 벡터 z를 잠재 벡터(latent vector)라고 함.

일반적으로 잠재 벡터의 차원은 입력 데이터의 차원보다 작음.

<br>

**디코더(Decoder)**

저차원 잠재 벡터 z에서 $$\hat{x}$$를 압축 해제를 수행.

$$\hat{x} = g(z)$$ 

<br>

**오토인코더(AutoEncoder)**

학습 데이터를 압축하고 해체할 수 있음.

새로운 데이터를 생성할 수 있는것은 아님.

인코더(Encoder)와 디코더(Decoder)가 연결되어 구성된 것.

VAE : 오토인코더를 생성 모델로 일반화하는 한가지 방법.

![k-nearnest](/image/ae.png)

<br>

**GAN(Generative Adversarial Network)**

생산적 적대 신경망.

훈련 데이터셋과 동일한 분포를 가진 새로운 데이터를 합성, 생성하는 것으로 비지도학습.

이미지-투-이미지 변환(image-to-image translation) : 입력 이미지에서 출력 이미지러 매핑하는 방법을 학습.

이미지 초해상도(image super-resolution) : 낮은 해상도의 이미지를 높은 해상도의 이미지로 변환.

이미지 인페이팅(image inpainting) : 이미지에서 누락된 부분을 재구성하는 방법을 학습.

생성자 신경망과 판별자(discriminator)라는 신경망으로 구성.

생성자는 판별자를 속이기위해 출력을 향상시키도록 학습하며 판별자는 더 잘 감지하도록 학습됨.

![k-nearnest](/image/gan.png)

#### GAN의 목적 함수 : $V(\theta^{(D)}, \theta^{(G)}) = E_{x-p_{data(x)}}[logD(x)] + E_{z-p_{z(z)}}[log(1 - D(G(z)))]$

$V(\theta^{(D)}, \theta^{(G)})$는 가치 함수(value function)

판별자(D)는 가치 함수 값에 대해 최대화하고 생성자(G)는 가치 함수 값에 대해 최소화해야 함.

D(x)는 입력 데이터 x가 진짜인지, 가짜(생성된 것)인지를 나타내는 확률.

첫번째 신경망의 가중치를 고정하고 두번째 신경망의 가중치를 최적화 한 다음 두번째 신경망의 가중치를 고정하고 첫번째 신경망의 가중치를 최적화함.







