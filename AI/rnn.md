# RNN

**시계열 데이터**

* 시간에 따라 변하는 데이터(주가/환율, 기온/습도)







**AR, MA, ARMA, ARIMA**

- 불규칙한 시계열 데이터에 규칙성을 부여하는 방법
- 시간을 독립 변수로 사용해 종속 변수를 예측







**순차 데이터(sequential data)**

* 텍스트나 시계열 데이터처럼 순서에 의미가 있는 데이터







**RNN(Recurrent Neural Network)**

![k-nearnest](/image/rnn.png)

* 순환 신경망(순차 데이터를 처리할때 사용)


* 이전 입력에 대한 결과가 다음에 오는 입력에 영향을 줌

#### $h_t = f_w(h_{t-1}, x_t)$

* 타임스텝(time step) : 샘플을 처리하는 한 단계
* 타임스텝이 오래될수록 순환되는 정보는 희미해짐
* RNN에서는 가중치가 2종류가 있음(입력과 곱해지는 가중치, 이전 타임스텝의 결과와 곱해지는 가중치)
* 입력값과 출력값을 어떻게 설정하냐에 따라 여러 상황에서 적용할 수 있음
* 1. 단일 입력, 다수 출력 : 이미지 캡션
  2. 다수 입력, 단일 출력 : 문장을 입력받아 뜻을 파악할때 활용(밥은 먹고 다니니? -> 안부 인사)
  3. 다수 입력, 다수 출력 : 번역기(예, 그게 다에요 -> yes, that's all)
* return_sequences=False로하면 단일 출력의 문제를 해결할 수 있음
* return_sequences=True로하면 다음층에 RNN 층이 있을 경우와 다수 출력의 문제를 해결할 수 있음

![k-nearnest](/image/rnn_n_1.png)                       ![k-nearnest](/image/rnn_n_n.png)

* RNN에서 가중치는 3가지로 분류됨
* 1. $W_{xh}$ : 입력층에서 은닉층으로 전달되는 가중치
  2. $W_{hh}$ : t 시점의 은닉층에서 t+1 시점의 은닉층으로 전달되는 가중치
  3. $W_{hy}$ : 은닉층에서 출력층으로 전달되는 가중치
* RNN에서 각각의 가중치는 모든 시점에서 동일함(가중치를 공유하기때문)






**LSTM(Long Short-Term Memory)**

RNN에서 기울기 소실 문제를 보완하 방법

